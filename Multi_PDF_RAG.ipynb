{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Multi PDF RAG Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PyPDF2 import PdfReader\n",
    "import fitz # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "\n",
    "# for efficient similarity search of vectors, which is useful for finding information quickly in large datasets\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Q6HOo4_KyCnyFkbf.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Processing PDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a user uploads one or more PDF files, the application reads each page of these documents and extracts the text, merging it into a single continuous string.\n",
    "\n",
    "Once the text is extracted, it is split into manageable chunks of 1000 characters each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_read_PyPDF2(pdf_doc):\n",
    "    text = ''\n",
    "    for pdf in pdf_doc:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def pdf_read_PyMuPDF(pdf_doc):\n",
    "    text = ''\n",
    "    for pdf in pdf_doc:\n",
    "        if type(pdf) == str: # read with path\n",
    "            pdf_reader = fitz.open(pdf)\n",
    "        else: # read with file object\n",
    "            pdf_reader = fitz.open(stream=pdf.read())\n",
    "            \n",
    "        for page_num in range(pdf_reader.page_count):\n",
    "            page = pdf_reader[page_num]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_docs = ['./demo_pdf_file/CV-Ho-Dang-Cao.pdf', './demo_pdf_file/academic_transcript.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hồ Đăng Cao\n",
      "AI Engineer Intern\n",
      "OBJECTIVE\n",
      "I am eager to apply for the AI Engineer Intern position at TMA Tech Group. I aspire to \n",
      "apply my academic knowledge in real-world scenarios while learning and further  \n",
      "developing my skills under the guidance of industry experts. I have continuously been  \n",
      "reading science papers, learning and working on projects in this field every day. With \n",
      "enthusiasm and a growth-oriented mindset, I am confident in my ability to contribute to \n",
      "the company’ s success and simultaneously advance my professional growth in a creative\n",
      "and challenging environment.\n",
      "SKILLS\n",
      "Programming language: Python, SQL.  \n",
      "Data crawling:  Selenium, BeautifulSoup.\n",
      "Data pr ocessing: Numpy , Pandas, Excel.\n",
      "Machine learning:  Pytorch, Sciki\n"
     ]
    }
   ],
   "source": [
    "print(pdf_read_PyPDF2([pdf_docs[0]])[:750])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hồ Đăng Cao\n",
      "AI Engineer Intern\n",
      "OBJECTIVE\n",
      "I am eager to apply for the AI Engineer Intern position at TMA Tech Group. I aspire to \n",
      "apply my academic knowledge in real-world scenarios while learning and further \n",
      "developing my skills under the guidance of industry experts. I have continuously been \n",
      "reading science papers, learning and working on projects in this field every day. With \n",
      "enthusiasm and a growth-oriented mindset, I am confident in my ability to contribute to \n",
      "the company’s success and simultaneously advance my professional growth in a creative\n",
      "and challenging environment.\n",
      "SKILLS\n",
      "Programming language: Python, SQL. \n",
      "Data crawling: Selenium, BeautifulSoup.\n",
      "Data processing: Numpy, Pandas, Excel.\n",
      "Machine learning: Pytorch, Scikit-learn,\n"
     ]
    }
   ],
   "source": [
    "raw_text = pdf_read_PyMuPDF([pdf_docs[0]])\n",
    "print(raw_text[:750])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:`\n",
    "- PyMuPDF text is cleaner.\n",
    "- PyPDF2 code is cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_read_PyMuPDF([pdf_docs[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgrade to read scanned PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanned PDFs typically contain images rather than text data that regular PDF text extraction libraries like PyPDF2, pdfplumber, and PyMuPDF can NOT handle. For scanned PDFs, use Optical Character Recognition (OCR) to extract text from images within the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolved_pdf_read_PyMuPDF(pdf_doc: list, ocr_config: str):\n",
    "    text = ''\n",
    "    for pdf in pdf_doc:\n",
    "        if type(pdf) == str: # read with path\n",
    "            pdf_reader = fitz.open(pdf)\n",
    "        else: # read with file object\n",
    "            pdf_reader = fitz.open(stream=pdf.read())\n",
    "            \n",
    "        for page_num in range(pdf_reader.page_count):\n",
    "            page = pdf_reader[page_num]            \n",
    "            text_page = page.get_text()\n",
    "\n",
    "            if not text_page.strip(): # if no text => scanned file\n",
    "                pix = page.get_pixmap()\n",
    "                img = Image.open(io.BytesIO(pix.tobytes('png')))\n",
    "                text_page = pytesseract.image_to_string(img, config=ocr_config)\n",
    "\n",
    "            text += text_page\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye\n",
      "\n",
      "=\n",
      "\n",
      "ose NATIONAL UNIVERSITY -HeMC\n",
      "\n",
      "SOCIALIST REPUBLIC OF VIETNAM\n",
      "\n",
      "i\n",
      "\n",
      "UNIVERSITY OF SCIENCE,\n",
      "\n",
      "Inde\n"
     ]
    }
   ],
   "source": [
    "ocr_config = r' --psm 11 --oem 3'\n",
    "\n",
    "raw_text = evolved_pdf_read_PyMuPDF([pdf_docs[1]], ocr_config)\n",
    "print(raw_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ye\\n\\n=\\n\\nose NATIONAL UNIVERSITY -HeMC\\n\\nSOCIALIST REPUBLIC OF VIETNAM\\n\\ni\\n\\nUNIVERSITY OF SCIENCE,\\n\\nIndependence - Fresom = Happiness\\n\\ni\\n\\n12\\n\\nACADEMIC TRANSCRIPT\\n\\nFall mame of student: HO DANG CAO\\n\\nStudent 1D: 20127482\\n\\nCourse: 2020-2024\\n\\nDate of bith\\n\\nDecember 15,2002,\\n\\nProgram\\n\\nachelor of Science\\n\\nPlace of bith\\n\\nHo Chi Mink City\\n\\nMajoe: Information Technology\\n\\n1 Jeourse 10\\n\\nCourse title\\n\\ncredits\\n\\nTO-Point | &Point\\n\\n‘grade\\n\\ngrade\\n\\nT]BAAO0003 | Hoth\\n\\n20\\n\\n200\\n\\n350\\n\\nFe Meolony\\n\\n2] BAAo0\\n\\nGeneral law',\n",
       " 'Ho Chi Mink City\\n\\nMajoe: Information Technology\\n\\n1 Jeourse 10\\n\\nCourse title\\n\\ncredits\\n\\nTO-Point | &Point\\n\\n‘grade\\n\\ngrade\\n\\nT]BAAO0003 | Hoth\\n\\n20\\n\\n200\\n\\n350\\n\\nFe Meolony\\n\\n2] BAAo0\\n\\nGeneral law\\n\\n30\\n\\n750\\n\\n325\\n\\n3] BAA0000S | Basie Economics\\n\\n20\\n\\n3.00\\n\\n400\\n\\n4|paaoo02r | Gymnastics 1\\n\\n4]\\n\\n20\\n\\n780\\n\\n340\\n\\n20\\n\\n310\\n\\n5|BAA000%2 | Gymnasties2\\n\\n400\\n\\n£6|BAA00030 | Nations Defence Education\\n\\n40\\n\\n267\\n\\nTH\\n\\n7|BAAoo101\\n\\n‘Marxist-Leninist Philosophy\\n\\n30\\n\\n750\\n\\n325\\n\\n8] BAAoOIO2 | Marxist\\n\\nist Politieal Economies\\n\\n20',\n",
       " '310\\n\\n5|BAA000%2 | Gymnasties2\\n\\n400\\n\\n£6|BAA00030 | Nations Defence Education\\n\\n40\\n\\n267\\n\\nTH\\n\\n7|BAAoo101\\n\\n‘Marxist-Leninist Philosophy\\n\\n30\\n\\n750\\n\\n325\\n\\n8] BAAoOIO2 | Marxist\\n\\nist Politieal Economies\\n\\n20\\n\\n8.00\\n\\n350\\n\\n9|BAA00103 | Scientific Socialism\\n\\n20\\n\\n6.00\\n\\n250\\n\\n10] BAAOOIOS | History of Vietnamese Communist Party\\n\\n20\\n\\n7.80\\n\\n3\\n\\ncry\\n\\n[escoo0os\\n\\nIntroduction to Information Technology\\n\\n40\\n\\n350\\n\\n3f5)\\n\\noN\\n\\n12]esc10001\\n\\n40\\n\\n300\\n\\nJoarngt\\n\\nIntroduction 1 Programming 1\\n\\nHOA He\\n\\n13]esc10002',\n",
       " '20\\n\\n7.80\\n\\n3\\n\\ncry\\n\\n[escoo0os\\n\\nIntroduction to Information Technology\\n\\n40\\n\\n350\\n\\n3f5)\\n\\noN\\n\\n12]esc10001\\n\\n40\\n\\n300\\n\\nJoarngt\\n\\nIntroduction 1 Programming 1\\n\\nHOA He\\n\\n13]esc10002\\n\\nInvroduction to Programming 2\\n\\n40\\n\\n6.00\\n\\n40\\n\\n2.00\\n\\nop\\n\\nTyna\\n\\n14] €SC10003_| Object-Oriented Programming\\n\\n13]CSC10004 | Data Structures and Algorithms\\n\\n40\\n\\n550\\n\\n225\\n\\n16] esc10006\\n\\nIntrodvtion to Databases\\n\\n40\\n\\n780\\n\\n330\\n\\n{€SC10007 | Operating Systems\\n\\n40\\n\\n2.00\\n\\n350\\n\\n40\\n\\n7.00\\n\\n300\\n\\n18] CSC10008_| Computer Networks',\n",
       " '40\\n\\n550\\n\\n225\\n\\n16] esc10006\\n\\nIntrodvtion to Databases\\n\\n40\\n\\n780\\n\\n330\\n\\n{€SC10007 | Operating Systems\\n\\n40\\n\\n2.00\\n\\n350\\n\\n40\\n\\n7.00\\n\\n300\\n\\n18] CSC10008_| Computer Networks\\n\\n19] CSC10009_| Computer Systems.\\n\\n20\\n\\n350\\n\\n375\\n\\n20\\n\\n[escioios\\n\\n40\\n\\n870\\n\\nData Visualization\\n\\n385\\n\\n21\\n\\nicscio1\\n\\n1\\n\\nInterpersonal Sil\\n\\n30\\n\\n7.00\\n\\n3.00\\n\\nmm\\n\\n220\\n\\n2\\n\\niescimst\\n\\nUndergraduate Thess\\n\\n“4.00\\n\\n2\\n\\n(csc1300\\n\\nIntroduction 1 Software Engineering\\n\\n40\\n\\n350\\n\\n375\\n\\n4\\n\\n1€5C14003 | Fundamentals of Artificial Intligence\\n\\n“40\\n\\n360\\n\\n380\\n\\n25',\n",
       " '7.00\\n\\n3.00\\n\\nmm\\n\\n220\\n\\n2\\n\\niescimst\\n\\nUndergraduate Thess\\n\\n“4.00\\n\\n2\\n\\n(csc1300\\n\\nIntroduction 1 Software Engineering\\n\\n40\\n\\n350\\n\\n375\\n\\n4\\n\\n1€5C14003 | Fundamentals of Artificial Intligence\\n\\n“40\\n\\n360\\n\\n380\\n\\n25\\n\\nJescr4oos\\n\\nData Mi\\n\\n1gand Applications\\n\\n40\\n\\n720\\n\\n340\\n\\n6\\n\\nJesc1ao0s\\n\\nInvrodutio 19 Machine Learning\\n\\n40\\n\\n9.00\\n\\n400\\n\\nn|\\n\\nlescisiie\\n\\nIntroduction wo Big Data\\n\\n40\\n\\n360\\n\\n3.80\\n\\nEy)\\n\\nesc\\n\\ntroduction to Data Seienee\\n\\n40\\n\\n3.00\\n\\n350\\n\\nFy\\n\\n{€Sc15004 | statistical Learning\\n\\n40\\n\\n250\\n\\n375\\n\\n30',\n",
       " \"40\\n\\n9.00\\n\\n400\\n\\nn|\\n\\nlescisiie\\n\\nIntroduction wo Big Data\\n\\n40\\n\\n360\\n\\n3.80\\n\\nEy)\\n\\nesc\\n\\ntroduction to Data Seienee\\n\\n40\\n\\n3.00\\n\\n350\\n\\nFy\\n\\n{€Sc15004 | statistical Learning\\n\\n40\\n\\n250\\n\\n375\\n\\n30\\n\\n[c8c17103 | Graph Mining\\n\\n40\\n\\n800\\n\\n400\\n\\nfy\\n\\n40\\n\\n940\\n\\n400\\n\\n|C8C17104 | Programming for Data Science\\n\\nBs\\n\\nMrti0000s | Celeuls 1\\n\\n40\\n\\n780\\n\\n325\\n\\nBy)\\n\\n1100006 | Calcul 2\\n\\n40\\n\\n980\\n\\n400\\n\\nEy\\n\\n'M11100007 | Applied Statistics for Engineers ond Selenss\\n\\n40\\n\\n970\\n\\n400\\n\\n3\\n\\n‘M1100008\\n\\n40\\n\\n9.00\\n\\n400\\n\\nneat Algebra\\n\\n6\",\n",
       " \"Mrti0000s | Celeuls 1\\n\\n40\\n\\n780\\n\\n325\\n\\nBy)\\n\\n1100006 | Calcul 2\\n\\n40\\n\\n980\\n\\n400\\n\\nEy\\n\\n'M11100007 | Applied Statistics for Engineers ond Selenss\\n\\n40\\n\\n970\\n\\n400\\n\\n3\\n\\n‘M1100008\\n\\n40\\n\\n9.00\\n\\n400\\n\\nneat Algebra\\n\\n6\\n\\n/s1100000 | Discrete Matbematis\\n\\n40\\n\\n650\\n\\n275\\n\\n”\\n\\n‘40\\n\\n9.00\\n\\n400\\n\\n|M11100087 | Applied Mathematics and Staines for Information Techno\\n\\naw\\n\\n|M1100058 | Combinaorat M\\n\\n40\\n\\n250\\n\\n375\\n\\n40\\n\\n750\\n\\n325\\n\\ny)\\n\\n1ry0000 | Gener! Physies\\n\\n=\\n\\nanes\\n\\n‘Sad with\\n\\nBeamscanner\\n/ETNAM NATIONAL UNIVERSITY - HMC\",\n",
       " 'aw\\n\\n|M1100058 | Combinaorat M\\n\\n40\\n\\n250\\n\\n375\\n\\n40\\n\\n750\\n\\n325\\n\\ny)\\n\\n1ry0000 | Gener! Physies\\n\\n=\\n\\nanes\\n\\n‘Sad with\\n\\nBeamscanner\\n/ETNAM NATIONAL UNIVERSITY - HMC\\n\\n‘SOCIALIST REPUBLIC OF VIETNAM.\\n\\nUNIVERSITY OF SCIENCE\\n\\nIndependence - Fredo - Happiness\\n\\n212\\n\\nACADEMIC TRANSCRIPT\\n\\ncou\\n\\n020-2024\\n\\nfeof student ;HO DANG CAO.\\n\\n‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|',\n",
       " '‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|\\n\\na [course 10\\n\\nrn\\n\\n920,\\n\\n400,\\n\\nZO] PRTYO0007 | Physics for Information Technolony\\n\\nHo Chi Minh City, October 14,2024\\n\\n‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with',\n",
       " '‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with\\n\\nBcamscanner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = get_chunks(raw_text)\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Searchable Text Database and Making Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application turns text chunks into vectors and saves these vectors locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SpacyEmbeddings(model_name='en_core_web_sm')\n",
    "\n",
    "def vector_store(text_chunks):\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local('faiss_db')\n",
    "    \n",
    "vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_extractor\n",
      "This tool is to give answer to queries from the pdf\n"
     ]
    }
   ],
   "source": [
    "new_db = FAISS.load_local('faiss_db', embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = new_db.as_retriever(search_kwargs={\"k\": 1}) # top_k=1 will return only the top chunk.\n",
    "retriever_chain = create_retriever_tool(retriever, 'pdf_extractor', 'This tool is to give answer to queries from the pdf')\n",
    "print(retriever_chain.name)\n",
    "print(retriever_chain.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|\\n\\na [course 10\\n\\nrn\\n\\n920,\\n\\n400,\\n\\nZO] PRTYO0007 | Physics for Information Technolony\\n\\nHo Chi Minh City, October 14,2024\\n\\n‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with'),\n",
       " Document(metadata={}, page_content='ye\\n\\n=\\n\\nose NATIONAL UNIVERSITY -HeMC\\n\\nSOCIALIST REPUBLIC OF VIETNAM\\n\\ni\\n\\nUNIVERSITY OF SCIENCE,\\n\\nIndependence - Fresom = Happiness\\n\\ni\\n\\n12\\n\\nACADEMIC TRANSCRIPT\\n\\nFall mame of student: HO DANG CAO\\n\\nStudent 1D: 20127482\\n\\nCourse: 2020-2024\\n\\nDate of bith\\n\\nDecember 15,2002,\\n\\nProgram\\n\\nachelor of Science\\n\\nPlace of bith\\n\\nHo Chi Mink City\\n\\nMajoe: Information Technology\\n\\n1 Jeourse 10\\n\\nCourse title\\n\\ncredits\\n\\nTO-Point | &Point\\n\\n‘grade\\n\\ngrade\\n\\nT]BAAO0003 | Hoth\\n\\n20\\n\\n200\\n\\n350\\n\\nFe Meolony\\n\\n2] BAAo0\\n\\nGeneral law'),\n",
       " Document(metadata={}, page_content='aw\\n\\n|M1100058 | Combinaorat M\\n\\n40\\n\\n250\\n\\n375\\n\\n40\\n\\n750\\n\\n325\\n\\ny)\\n\\n1ry0000 | Gener! Physies\\n\\n=\\n\\nanes\\n\\n‘Sad with\\n\\nBeamscanner\\n/ETNAM NATIONAL UNIVERSITY - HMC\\n\\n‘SOCIALIST REPUBLIC OF VIETNAM.\\n\\nUNIVERSITY OF SCIENCE\\n\\nIndependence - Fredo - Happiness\\n\\n212\\n\\nACADEMIC TRANSCRIPT\\n\\ncou\\n\\n020-2024\\n\\nfeof student ;HO DANG CAO.\\n\\n‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|'),\n",
       " Document(metadata={}, page_content='‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with\\n\\nBcamscanner')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = ['show GPA','list the projects titles','December']\n",
    "new_db.similarity_search(queries[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|\\n\\na [course 10\\n\\nrn\\n\\n920,\\n\\n400,\\n\\nZO] PRTYO0007 | Physics for Information Technolony\\n\\nHo Chi Minh City, October 14,2024\\n\\n‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(queries[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‘Student ID; 20127482\\n\\nBachel\\n\\nof Science\\n\\nori\\n\\nDecember 15,2002\\n\\nProgram\\n\\nHo Chi Minh City\\n\\nMajor: Information Technology\\n\\nfbi\\n\\ncredits\\n\\nTo-point | +\\n\\n‘course title\\n\\ngrade_|_grade_|\\n\\na [course 10\\n\\nrn\\n\\n920,\\n\\n400,\\n\\nZO] PRTYO0007 | Physics for Information Technolony\\n\\nHo Chi Minh City, October 14,2024\\n\\n‘otal Accumulated Credits:\\n\\n7\\n\\nBY ORDEROF RECTOR\\n\\nGrade Point Average creepntain\\n\\npepury i\\n\\n\\\\CADEMIC|AFFAIRS OFFICE,\\n\\nGrade Pint Average aerguiatsate 3.56\\n\\nmoe\\n\\nwi\\n\\nPHAM THUTHUAN\\n\\nby\\n\\n‘Sad with'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain.invoke(queries[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Conversational AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AI Configuration**: The app sets up a conversational AI to answer questions based on the PDF content it has processed.\n",
    "- **Conversation Chain**: The AI uses a set of prompts to understand the context and provide accurate responses to user queries. If the answer to a question isn’t available in the text, the AI is programmed to respond with “answer is not available in the context,” ensuring that users do not receive incorrect information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOllama(model='mistral', quantization='8bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    (\"system\", f\"You are an AI assistant with access to the following tool: {retriever_chain.name}. {retriever_chain.description}\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document provided doesn't seem to contain any project titles as it appears to be a student's academic transcript or certificate. Project titles would typically be found in documents related to research, coursework, or assignments where students conduct independent study or complete group projects. If you have a different PDF containing project titles, I'd be happy to help with that!\n"
     ]
    }
   ],
   "source": [
    "def get_conversational_chain(retriever_chain, query):\n",
    "    related_chunk = retriever_chain.invoke({'query': query})\n",
    "    history.append((\"user\", \"Given document: {related_chunk}\"))\n",
    "    history.append((\"user\", \"{query}\"))\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(history)\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke({'related_chunk':related_chunk, 'query':query}, temperature=0).strip()\n",
    "    history.append((\"assistant\", response))\n",
    "\n",
    "    return response\n",
    "\n",
    "query = 'list the projects titles'\n",
    "response = get_conversational_chain(retriever_chain, query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided document, the student's Grade Point Average (GPA) is 3.56. In many educational systems, a GPA between 3.0 and 4.0 is considered average to good, so it seems like the student's performance is generally good. However, keep in mind that different institutions have their own grading criteria, so the interpretation of these grades may vary. It would be best to consult with an academic advisor or the institution for a more accurate assessment of the student's performance.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'assess the performance. good or bad?'\n",
    "get_conversational_chain(retriever_chain, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker build -t pdf_rag .\n",
    "# !docker run -it pdf_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Building a Multi PDF RAG Chatbot: Langchain, Streamlit with code](https://blog.gopenai.com/building-a-multi-pdf-rag-chatbot-langchain-streamlit-with-code-d21d0a1cf9e5)\n",
    "\n",
    "[Query SQL Database Using Natural Language with Llama 3 and LangChain](https://medium.com/dev-genius/query-sql-database-using-natural-language-with-llama-3-and-langchain-a310e6d7dc14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
